[
  {
    "objectID": "posts/post-with-code/post.html",
    "href": "posts/post-with-code/post.html",
    "title": "Jupyter Testing",
    "section": "",
    "text": "!pwd\n\n/Users/daniel.hunter/code/myblog/posts/post-with-code\n\n\n\nimg = Image.open(Path.home() / 'Downloads' / 'AvatarAI.me' / '61.jpg')\n\n\nimg\n\n\n\n\n\nimport numpy as np\nimport torch\nfrom torchvision import transforms\n\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\n\npreprocess = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n\n\ndef deprocess(image_np):\n    image_np = image_np.squeeze().transpose(1, 2, 0)\n    image_np = image_np * std.reshape((1, 1, 3)) + mean.reshape((1, 1, 3))\n    image_np = np.clip(image_np, 0.0, 255.0)\n    return image_np\n\n\ndef clip(image_tensor):\n    for c in range(3):\n        m, s = mean[c], std[c]\n        image_tensor[0, c] = torch.clamp(image_tensor[0, c], -m / s, (1 - m) / s)\n    return image_tensor\n\n\nfrom torch.autograd import Variable\nfrom tqdm.auto import tqdm\nimport scipy.ndimage as nd\n\n\ndef dream(image, model, iterations, lr):\n    \"\"\" Updates the image to maximize outputs for n iterations \"\"\"\n    Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n    image = Variable(Tensor(image), requires_grad=True)\n    for i in range(iterations):\n        model.zero_grad()\n        out = model(image)\n        # label = [00000,1,00000]\n        label = torch.zeros(1, dtype=torch.long)\n        label[0] = 779\n        loss = nn.CrossEntropyLoss()(out, label)\n        # import pdb ; pdb.set_trace()\n        # loss = out.norm()\n        loss.backward()\n        avg_grad = np.abs(image.grad.data.cpu().numpy()).mean()\n        norm_lr = lr / avg_grad\n        image.data += norm_lr * image.grad.data\n        image.data = clip(image.data)\n        image.grad.data.zero_()\n    return image.cpu().data.numpy()\n\n\ndef deep_dream(image, model, iterations, lr, octave_scale, num_octaves):\n    \"\"\" Main deep dream method \"\"\"\n    image = preprocess(image).unsqueeze(0).cpu().data.numpy()\n\n    # Extract image representations for each octave\n    octaves = [image]\n    for _ in range(num_octaves - 1):\n        octaves.append(nd.zoom(octaves[-1], (1, 1, 1 / octave_scale, 1 / octave_scale), order=1))\n\n    detail = np.zeros_like(octaves[-1])\n    for octave, octave_base in enumerate(tqdm(octaves[::-1], desc=\"Dreaming\")):\n        if octave > 0:\n            # Upsample detail to new octave dimension\n            detail = nd.zoom(detail, np.array(octave_base.shape) / np.array(detail.shape), order=1)\n        # Add deep dream detail from previous octave to new base\n        input_image = octave_base + detail\n        # Get new deep dream image\n        dreamed_image = dream(input_image, model, iterations, lr)\n        # Extract deep dream details\n        detail = dreamed_image - octave_base\n\n    return deprocess(dreamed_image)\n\n\nimport torch\nfrom torch import nn\nfrom torchvision import models\n\n# Define the model\nnetwork = models.vgg19(weights=models.VGG19_Weights.DEFAULT)\n# layers = list(network.features.children())\nmodel = network # nn.Sequential(*layers[: (27 + 1)])\nif torch.cuda.is_available():\n    model = model.cuda()\n# print(network)\n\n# Extract deep dream image\ndreamed_image = deep_dream(\n    img,\n    model,\n    iterations=30,\n    lr=0.03,\n    octave_scale=1.4,\n    num_octaves=5,\n)\n\n\n\n\n\nviz(dreamed_image)\n\n\n\n\n\nnp.array(img).shape\n\n(512, 512, 3)\n\n\n\nnd.zoom(np.array(img), (1 / 1.4, 1 / 1.4, 1), order=1).shape\n\n(366, 366, 3)\n\n\n\nlen(dreamed_image)\n\n10\n\n\n\nfrom more_itertools import zip_equal\nimport matplotlib.pyplot as plt\n\ndef prep_img(arr):\n    if isinstance(arr, Image.Image):\n        arr = np.array(arr)\n    arr = arr.squeeze()\n    if arr.shape[0] == 3:\n        arr = arr.transpose((1,2,0))\n    _H, _W, C = arr.shape\n    assert C == 3, arr.shape\n    if arr.dtype in [np.float32, np.float64]:\n        arr = np.clip(a=arr, a_min=0, a_max=1)\n    elif arr.dtype in [np.uint8]:\n        arr = np.clip(a=arr, a_min=0, a_max=255)\n    else:\n        raise ValueError(arr.dtype)\n    return arr\n\ndef viz(*arrs, ncols=1):\n    fig, axs = plt.subplots(nrows=len(arrs), ncols=ncols, figsize=(20,20), squeeze=False)\n    for arr, ax in zip_equal(arrs, axs.ravel()):\n        # import pdb ; pdb.set_trace()\n        ax.imshow(prep_img(arr))\n\n\nviz(\n    # dreamed_image[0],\n    # dreamed_image[5],\n    # dreamed_image[9],\n    nd.zoom(np.array(img), (1 / 3, 1 / 3, 1), order=1),\n    img,\n)"
  },
  {
    "objectID": "posts/deep-dream/post.html",
    "href": "posts/deep-dream/post.html",
    "title": "Getting Quarto to execute code blocks",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus."
  },
  {
    "objectID": "posts/deep-dream/post.html#merriweather",
    "href": "posts/deep-dream/post.html#merriweather",
    "title": "Getting Quarto to execute code blocks",
    "section": "Merriweather",
    "text": "Merriweather\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus."
  },
  {
    "objectID": "posts/deep-dream/post.html#code",
    "href": "posts/deep-dream/post.html#code",
    "title": "Getting Quarto to execute code blocks",
    "section": "3 - Code",
    "text": "3 - Code\nThis is inline code plus a small code chunk.\n\nprint(f'Daniel has {2+2=} apples')\n\nDaniel has 2+2=4 apples"
  },
  {
    "objectID": "posts/welcome/post.html",
    "href": "posts/welcome/post.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Jupyter Testing\n\n\n\n\n\nReviving Deep Dream\n\n\n\n\n\n\nNov 4, 2022\n\n\nDaniel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Quarto to execute code blocks\n\n\n\n\n\nReviving Deep Dream\n\n\n\n\n\n\nOct 5, 2022\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\n\n\n\n\nOct 4, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Daniel",
    "section": "",
    "text": "I’m a machine learning engineer.\nI shipped many safety critical features at Tesla Autopilot, working on FSD.\nI helped on the transition team at Twitter.\nI like to kite surf and tweet too much.\nI enjoy bike shedding over knowledge management systems."
  }
]